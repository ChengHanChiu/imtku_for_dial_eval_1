{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
      "Requirement already satisfied: tokenizers==0.5.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.5)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.27.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.7.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (45.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  bert-chinese-qa.zip\n",
      "warning [bert-chinese-qa.zip]:  403000 extra bytes at beginning or within zipfile\n",
      "  (attempting to process anyway)\n",
      " extracting: bert-chinese-qa/added_tokens.json  \n",
      "  inflating: bert-chinese-qa/config.json  \n",
      "  inflating: bert-chinese-qa/nbest_predictions_.json  \n",
      "  inflating: bert-chinese-qa/predictions_.json  \n",
      "  inflating: bert-chinese-qa/pytorch_model.bin  \n",
      "  inflating: bert-chinese-qa/special_tokens_map.json  \n",
      "  inflating: bert-chinese-qa/training_args.bin  \n",
      "  inflating: bert-chinese-qa/vocab.txt  \n"
     ]
    }
   ],
   "source": [
    "!rm -rf bert-chinese-qa*\n",
    "!wget -q --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1GQtGFd-1AvZHZuYckhA3xqvvpDk-x5DW' -O bert-chinese-qa.zip\n",
    "!unzip bert-chinese-qa.zip -d bert-chinese-qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /usr/local/lib/python3.6/dist-packages (9.6.0)\n",
      "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.11)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.7.2)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (45.1.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube\n",
    "!pip install pydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'BERT-Practice' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/stg880631/BERT-Practice.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\n",
      "bert-chinese-qa  bert-chinese-qa.zip  BERT-Practice  drive  sample_data\n",
      "\n",
      "./bert-chinese-qa:\n",
      "added_tokens.json\t predictions_.json\t  training_args.bin\n",
      "config.json\t\t pytorch_model.bin\t  vocab.txt\n",
      "nbest_predictions_.json  special_tokens_map.json\n",
      "\n",
      "./BERT-Practice:\n",
      "DRCD_dev.json\t\t   FGC_release_A_answers.json  README.md\n",
      "DRCD_test.json\t\t   FGC_release_A.csv\t       search.dev.json\n",
      "DRCD_training.json\t   FGC_release_A.json\t       search.test.json\n",
      "DRCDtraining_output.csv    FGC_release_B_answers.json  search.train.json\n",
      "FGC_release_A_1.csv\t   FGC_release_B.json\n",
      "FGC_release_A_answers.csv  output.csv\n",
      "\n",
      "./drive:\n",
      "'My Drive'\n",
      "\n",
      "'./drive/My Drive':\n",
      " 1062-MI1A-期中考.pdf.gdoc\n",
      " 1097367_三階段三王.gdoc\n",
      " 1138883_DQ論文重點.gdoc\n",
      " 1.jpg\n",
      " 20170927406630136谷昭賢作業.rar\n",
      " 2019_情感對話機器人\n",
      " 245446.jpg\n",
      " 272601_資訊概論中文答案.txt.gdoc\n",
      " 2.jpg\n",
      "'31084_實驗原理 (1).txt.gdoc'\n",
      " 31084_實驗原理.txt.gdoc\n",
      "'37712_飲食文化講稿 (1).txt.gdoc'\n",
      "'37712_飲食文化講稿 (2).txt.gdoc'\n",
      "'37712_飲食文化講稿 (3).txt.gdoc'\n",
      "'37712_飲食文化講稿 (4).txt.gdoc'\n",
      " 37712_飲食文化講稿.txt.gdoc\n",
      " 40739_跑流考題目.txt.gdoc\n",
      "'449336_packet tracer_基本指令.gdoc'\n",
      "'53929_跑流考題目 (1).txt.gdoc'\n",
      " 53929_跑流考題目.txt.gdoc\n",
      " 57177_體育時間.txt.gdoc\n",
      "'57178_通識 (1).txt.gdoc'\n",
      "'57178_通識 (2).txt.gdoc'\n",
      "'57178_通識 (3).txt.gdoc'\n",
      " 57178_通識.txt.gdoc\n",
      " 636780_專題概念.gdoc\n",
      "'7-ELEVEN 交貨便服務單.pdf'\n",
      " 923460_科技大擂台與AI對話製作方向.gdoc\n",
      " 983228_pytorch.gdoc\n",
      " 985844_忙碌生活.gdoc\n",
      "'Colab Notebooks'\n",
      "'CSF校園團報系統-考生報名(TQC).pdf'\n",
      " Data\n",
      "'How to get started with Drive.pdf'\n",
      " hwk10-1.jpg\n",
      " hwk10-2.jpg\n",
      " hwk2-1.jpg\n",
      " hwk2-2.jpg\n",
      " hwk3-1.jpg\n",
      " hwk3-2.jpg\n",
      " hwk4-1.jpg\n",
      " hwk4-2.jpg\n",
      " hwk5-1.jpg\n",
      " hwk5-2.jpg\n",
      " hwk6-1.jpg\n",
      " hwk6-2.jpg\n",
      " hwk7-1.jpg\n",
      " hwk7-2.jpg\n",
      " hwk8-1.jpg\n",
      " hwk8-2.jpg\n",
      " hwk9-1.jpg\n",
      " hwk9-2.jpg\n",
      " IMAG2558.jpg\n",
      " LINE_Android-backup-chat-142402620259.zip\n",
      "'Main (10).java'\n",
      "'Main (11).java'\n",
      "'Main (12).java'\n",
      "'Main (13).java'\n",
      "'Main (14).java'\n",
      "'Main (15).java'\n",
      "'Main (16).java'\n",
      "'Main (17).java'\n",
      "'Main (18).java'\n",
      "'Main (19).java'\n",
      "'Main (1).java'\n",
      "'Main (2).java'\n",
      "'Main (3).java'\n",
      "'Main (4).java'\n",
      "'Main (5).java'\n",
      "'Main (6).java'\n",
      "'Main (7).java'\n",
      "'Main (8).java'\n",
      "'Main (9).java'\n",
      " Main.java\n",
      " Portfolio\n",
      "'Produce (1).mpg'\n",
      " Produce.mpg\n",
      "'中山高中 外木山影片'\n",
      " 作業.rar\n",
      "'學長姐論文P13~P15& NTCIR大綱.gdoc'\n",
      " 學長姐論文P5~P8.gdoc\n",
      " 學長姐論文P9~P13公式完.gdoc\n",
      "'未命名文件 (10).gdoc'\n",
      "'未命名文件 (1).gdoc'\n",
      "'未命名文件 (2).gdoc'\n",
      "'未命名文件 (3).gdoc'\n",
      "'未命名文件 (4).gdoc'\n",
      "'未命名文件 (5).gdoc'\n",
      "'未命名文件 (6).gdoc'\n",
      "'未命名文件 (7).gdoc'\n",
      "'未命名文件 (8).gdoc'\n",
      "'未命名文件 (9).gdoc'\n",
      " 未命名文件.gdoc\n",
      " 模擬聯合國照片.rar\n",
      " 返服\n",
      " 電子競技和電競選手認知.gform\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人':\n",
      "BERT訓練程式碼實作問題\t二下暑假-預習事項  進度報告\n",
      "CompetitionTestFile\t產學合作資料\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/BERT訓練程式碼實作問題':\n",
      "QA001.jpg  QA003.jpg  QA005.jpg  QA007.jpg  完整BERT程式碼.gdoc\n",
      "QA002.jpg  QA004.jpg  QA006.jpg  QA008.jpg\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/CompetitionTestFile':\n",
      "'Copy of NTUBertTest.ipynb'   FGC_release_A.json\n",
      " FGC_release_A_answers.csv    fgc-training-data-1.zip\n",
      " FGC_release_A_answers.json   fgc-training-data-2-v2.7z\n",
      " FGC_release_A.csv\t      QA集.xlsx\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項':\n",
      " 2019_AI_for_Financial_Services_Innovation_and_Application_20190419.pptx\n",
      " 2019_AI_Humanoid_Conversational_Robo-Advisor_20190506.pptx\n",
      " 2019_AI_Robo-Advisor_and_Conversational_Commerce_20190102.pptx\n",
      "'NTCIR 情緒對話系統'\n",
      " 人工智慧\n",
      " 學習管道\n",
      " 學長姐專題觀摩\n",
      " 歷屆學長姐專題\n",
      " 歷屆專題資料整理\n",
      " 組員個資\n",
      " 選課推薦.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/NTCIR 情緒對話系統':\n",
      "NTCIR情緒對話系統.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/人工智慧':\n",
      "竹間智能Emotibot.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/學習管道':\n",
      "深度學習、機器學習  自學Python\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/學習管道/深度學習、機器學習':\n",
      " AI人工智慧.gdoc\t\t   'Deep Learning, Machine Learning.gdoc'\n",
      "'Coursera- Machine Learning.gdoc'   Keras.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/學習管道/自學Python':\n",
      "'Python Flask.gdoc'   線上Python網站.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/學長姐專題觀摩':\n",
      "IMG_1455.HEIC  IMG_1466.HEIC  IMG_1476.HEIC  IMG_1489.HEIC  IMG_1517.MOV\n",
      "IMG_1456.HEIC  IMG_1467.HEIC  IMG_1477.HEIC  IMG_1490.HEIC  IMG_1520.HEIC\n",
      "IMG_1457.HEIC  IMG_1468.HEIC  IMG_1479.HEIC  IMG_1491.HEIC  IMG_1521.MOV\n",
      "IMG_1458.HEIC  IMG_1469.HEIC  IMG_1481.HEIC  IMG_1492.HEIC  IMG_1522.MOV\n",
      "IMG_1460.HEIC  IMG_1470.HEIC  IMG_1483.HEIC  IMG_1510.HEIC  IMG_1525.HEIC\n",
      "IMG_1461.HEIC  IMG_1471.HEIC  IMG_1484.HEIC  IMG_1511.HEIC  IMG_1526.HEIC\n",
      "IMG_1462.HEIC  IMG_1472.HEIC  IMG_1485.HEIC  IMG_1512.HEIC  IMG_1527.HEIC\n",
      "IMG_1463.HEIC  IMG_1473.HEIC  IMG_1486.HEIC  IMG_1514.HEIC  IMG_1528.HEIC\n",
      "IMG_1464.HEIC  IMG_1474.HEIC  IMG_1487.HEIC  IMG_1515.HEIC  IMG_1530.HEIC\n",
      "IMG_1465.HEIC  IMG_1475.HEIC  IMG_1488.HEIC  IMG_1516.HEIC\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/歷屆學長姐專題':\n",
      "2016_AtmosCare+  2017_MissFinRobart  2018_AIWISFIN\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/歷屆學長姐專題/2016_AtmosCare+':\n",
      "AtmosCare+.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/歷屆學長姐專題/2017_MissFinRobart':\n",
      "MissFinRobart.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/歷屆學長姐專題/2018_AIWISFIN':\n",
      "AIWISFIN.gdoc\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/歷屆專題資料整理':\n",
      "歷屆專題資料整理.docx\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/二下暑假-預習事項/組員個資':\n",
      "313131_SD專題小組名單.docx\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/產學合作資料':\n",
      "產學合作報名資料.docx\n",
      "\n",
      "'./drive/My Drive/2019_情感對話機器人/進度報告':\n",
      "20191017報告簡報.pdf\t    20191031資管周觀摩心得.pptx  20200219報告簡報.pdf\n",
      "20191017報告簡報.pptx\t    2019專題競賽觀看心得.pdf\t 20200219報告簡報.pptx\n",
      "20191031資管周觀摩心得.pdf  2019專題競賽觀看心得.pptx\n",
      "\n",
      "'./drive/My Drive/Colab Notebooks':\n",
      "'1 19 BERT.ipynb'\t\t   'DUReader Json轉Csv.ipynb'\n",
      " 1219BERT.ipynb\t\t\t    FGC_release_A.json\n",
      "'1 22 BERT.ipynb'\t\t   'lstm(dataset1).ipynb'\n",
      "'2 2 BERT.ipynb'\t\t   'NTUBertTest1203(ChenHan).ipynb'\n",
      "'2 4 BERT2.ipynb'\t\t   'NTUBertTest(Mine)20191212.ipynb'\n",
      "'2 4 BERT.ipynb'\t\t    python101_2019_11_21.ipynb\n",
      " CopyBERT.ipynb\t\t\t    TransformData.ipynb\n",
      "'Copy of CopyBERT.ipynb'\t    Untitled\n",
      "'Copy of Copy of Json轉Csv.ipynb'   Untitled0.ipynb\n",
      "'Copy of NTUBertTest (1).ipynb'     Untitled1.ipynb\n",
      "'Copy of NTUBertTest.ipynb'\t    Untitled2.ipynb\n",
      "'Copy of WebCrawler (1).ipynb'\t    Untitled3.ipynb\n",
      "'Copy of WebCrawler.ipynb'\t    Untitled4.ipynb\n",
      "'Copy of 輸出答案.ipynb'\t    WebCrawler.ipynb\n",
      "'cudatype2 4 BERT.ipynb'\n",
      "\n",
      "'./drive/My Drive/Data':\n",
      " bert-chinese-qa\t      FGC_release_A.csv\n",
      " bert-chinese-qa.zip\t      FGC_release_A.json\n",
      " BERT-Practice\t\t      fgc-training-data-1.zip\n",
      " DRCD_dev.json\t\t      io_test1.txt\n",
      " DRCD_test.json\t\t     'newDRCDtraining_output .csv'\n",
      " DRCD_training.json\t      output2.csv\n",
      " DRCDtraining_output2.csv     output.csv\n",
      " DRCDtraining_output3.csv     output.gsheet\n",
      " DRCDtraining_output.csv      search.dev.json\n",
      " FGC_release_A_1.csv\t      search.test.json\n",
      " FGC_release_A_1.json\t      search.train.json\n",
      " FGC_release_A_answers.json   train.tsv\n",
      "\n",
      "'./drive/My Drive/Data/bert-chinese-qa':\n",
      "added_tokens.json\t predictions_.json\t  training_args.bin\n",
      "config.json\t\t pytorch_model.bin\t  vocab.txt\n",
      "nbest_predictions_.json  special_tokens_map.json\n",
      "\n",
      "'./drive/My Drive/Data/BERT-Practice':\n",
      "DRCD_dev.json\t\t   FGC_release_A_answers.json  README.md\n",
      "DRCD_test.json\t\t   FGC_release_A.csv\t       search.dev.json\n",
      "DRCD_training.json\t   FGC_release_A.json\t       search.test.json\n",
      "DRCDtraining_output.csv    FGC_release_B_answers.json  search.train.json\n",
      "FGC_release_A_1.csv\t   FGC_release_B.json\n",
      "FGC_release_A_answers.csv  output.csv\n",
      "\n",
      "'./drive/My Drive/Portfolio':\n",
      " Dataset1\t\t\t\t  retData2.csv\n",
      " Dataset2\t\t\t\t  retData3.csv\n",
      " Figures\t\t\t\t  retData4.csv\n",
      " Forecasts\t\t\t\t  retData5.csv\n",
      "'lstm(dataset1).ipynb'\t\t\t  retData6.csv\n",
      "'lstm(dataset2).ipynb'\t\t\t  retData7.csv\n",
      "'Markowitz_Black-Litterment test.ipynb'   retData8.csv\n",
      " protofolio_comparison_test1.ipynb\t 'run_lstm(dataset1).ipynb'\n",
      " protofolio_comparison_test.ipynb\t 'run_lstm(dataset2).ipynb'\n",
      " retData1.csv\n",
      "\n",
      "'./drive/My Drive/Portfolio/Dataset1':\n",
      "001_SPY.csv  006_EWU.csv  011_EWW.csv  017_EWO.csv  023_XLK.csv  033_IWB.csv\n",
      "002_MDY.csv  007_EWH.csv  012_EWI.csv  018_EWN.csv  024_XLE.csv  036_IWM.csv\n",
      "003_EWJ.csv  008_EWA.csv  014_EWS.csv  019_EWK.csv  025_XLY.csv\n",
      "004_EWG.csv  009_EWP.csv  015_EWD.csv  020_DIA.csv  026_XLI.csv\n",
      "005_EWC.csv  010_EWL.csv  016_EWM.csv  021_XLF.csv  027_XLP.csv\n",
      "\n",
      "'./drive/My Drive/Portfolio/Dataset2':\n",
      "0050_ETF.csv  0052_ETF.csv  0054_ETF.csv  0056_ETF.csv\n",
      "0051_ETF.csv  0053_ETF.csv  0055_ETF.csv  0057_ETF.csv\n",
      "\n",
      "'./drive/My Drive/Portfolio/Figures':\n",
      "001_SPY_1d_boxplot_20190729_101727.png\t 011_EWW_1d_loss_20190729_114243.png\n",
      "001_SPY_1d_lnrts_20190729_101727.png\t 011_EWW_1d_price_20190729_114249.png\n",
      "001_SPY_1d_loss_20190729_101722.png\t 011_EWW_1d_rmse_20190729_114243.png\n",
      "001_SPY_1d_price_20190729_101728.png\t 012_EWI_1d_boxplot_20190729_115116.png\n",
      "001_SPY_1d_rmse_20190729_101723.png\t 012_EWI_1d_lnrts_20190729_115116.png\n",
      "002_MDY_1d_boxplot_20190729_102608.png\t 012_EWI_1d_loss_20190729_115112.png\n",
      "002_MDY_1d_lnrts_20190729_102608.png\t 012_EWI_1d_price_20190729_115117.png\n",
      "002_MDY_1d_loss_20190729_102604.png\t 012_EWI_1d_rmse_20190729_115113.png\n",
      "002_MDY_1d_price_20190729_102609.png\t 014_EWS_1d_boxplot_20190729_115940.png\n",
      "002_MDY_1d_rmse_20190729_102604.png\t 014_EWS_1d_lnrts_20190729_115941.png\n",
      "003_EWJ_1d_boxplot_20190729_103444.png\t 014_EWS_1d_loss_20190729_115936.png\n",
      "003_EWJ_1d_lnrts_20190729_103444.png\t 014_EWS_1d_price_20190729_115941.png\n",
      "003_EWJ_1d_loss_20190729_103439.png\t 014_EWS_1d_rmse_20190729_115936.png\n",
      "003_EWJ_1d_price_20190729_103445.png\t 015_EWD_1d_boxplot_20190729_120759.png\n",
      "003_EWJ_1d_rmse_20190729_103440.png\t 015_EWD_1d_lnrts_20190729_120759.png\n",
      "004_EWG_1d_boxplot_20190729_104320.png\t 015_EWD_1d_loss_20190729_120755.png\n",
      "004_EWG_1d_lnrts_20190729_104320.png\t 015_EWD_1d_price_20190729_120800.png\n",
      "004_EWG_1d_loss_20190729_104316.png\t 015_EWD_1d_rmse_20190729_120756.png\n",
      "004_EWG_1d_price_20190729_104321.png\t 016_EWM_1d_boxplot_20190729_121633.png\n",
      "004_EWG_1d_rmse_20190729_104316.png\t 016_EWM_1d_lnrts_20190729_121633.png\n",
      "0050_ETF_1d_boxplot_20190730_080023.png  016_EWM_1d_loss_20190729_121628.png\n",
      "0050_ETF_1d_lnrts_20190730_080023.png\t 016_EWM_1d_price_20190729_121634.png\n",
      "0050_ETF_1d_loss_20190730_080018.png\t 016_EWM_1d_rmse_20190729_121628.png\n",
      "0050_ETF_1d_price_20190730_080024.png\t 017_EWO_1d_boxplot_20190729_122518.png\n",
      "0050_ETF_1d_rmse_20190730_080019.png\t 017_EWO_1d_lnrts_20190729_122518.png\n",
      "0051_ETF_1d_boxplot_20190730_080906.png  017_EWO_1d_loss_20190729_122514.png\n",
      "0051_ETF_1d_lnrts_20190730_080907.png\t 017_EWO_1d_price_20190729_122519.png\n",
      "0051_ETF_1d_loss_20190730_080901.png\t 017_EWO_1d_rmse_20190729_122514.png\n",
      "0051_ETF_1d_price_20190730_080908.png\t 018_EWN_1d_boxplot_20190729_123404.png\n",
      "0051_ETF_1d_rmse_20190730_080902.png\t 018_EWN_1d_lnrts_20190729_123405.png\n",
      "0052_ETF_1d_boxplot_20190730_081953.png  018_EWN_1d_loss_20190729_123359.png\n",
      "0052_ETF_1d_lnrts_20190730_081953.png\t 018_EWN_1d_price_20190729_123405.png\n",
      "0052_ETF_1d_loss_20190730_081948.png\t 018_EWN_1d_rmse_20190729_123359.png\n",
      "0052_ETF_1d_price_20190730_081954.png\t 019_EWK_1d_boxplot_20190729_124248.png\n",
      "0052_ETF_1d_rmse_20190730_081949.png\t 019_EWK_1d_lnrts_20190729_124248.png\n",
      "0053_ETF_1d_boxplot_20190730_082832.png  019_EWK_1d_loss_20190729_124244.png\n",
      "0053_ETF_1d_lnrts_20190730_082832.png\t 019_EWK_1d_price_20190729_124249.png\n",
      "0053_ETF_1d_loss_20190730_082827.png\t 019_EWK_1d_rmse_20190729_124244.png\n",
      "0053_ETF_1d_price_20190730_082833.png\t 020_DIA_1d_boxplot_20190729_125137.png\n",
      "0053_ETF_1d_rmse_20190730_082828.png\t 020_DIA_1d_lnrts_20190729_125138.png\n",
      "0054_ETF_1d_boxplot_20190730_083709.png  020_DIA_1d_loss_20190729_125132.png\n",
      "0054_ETF_1d_lnrts_20190730_083710.png\t 020_DIA_1d_price_20190729_125138.png\n",
      "0054_ETF_1d_loss_20190730_083705.png\t 020_DIA_1d_rmse_20190729_125133.png\n",
      "0054_ETF_1d_price_20190730_083710.png\t 021_XLF_1d_boxplot_20190729_130030.png\n",
      "0054_ETF_1d_rmse_20190730_083705.png\t 021_XLF_1d_lnrts_20190729_130031.png\n",
      "0055_ETF_1d_boxplot_20190730_084548.png  021_XLF_1d_loss_20190729_130026.png\n",
      "0055_ETF_1d_lnrts_20190730_084548.png\t 021_XLF_1d_price_20190729_130031.png\n",
      "0055_ETF_1d_loss_20190730_084543.png\t 021_XLF_1d_rmse_20190729_130027.png\n",
      "0055_ETF_1d_price_20190730_084549.png\t 023_XLK_1d_boxplot_20190729_130918.png\n",
      "0055_ETF_1d_rmse_20190730_084544.png\t 023_XLK_1d_lnrts_20190729_130919.png\n",
      "0056_ETF_1d_boxplot_20190730_085424.png  023_XLK_1d_loss_20190729_130913.png\n",
      "0056_ETF_1d_lnrts_20190730_085424.png\t 023_XLK_1d_price_20190729_130919.png\n",
      "0056_ETF_1d_loss_20190730_085419.png\t 023_XLK_1d_rmse_20190729_130914.png\n",
      "0056_ETF_1d_price_20190730_085425.png\t 024_XLE_1d_boxplot_20190729_131807.png\n",
      "0056_ETF_1d_rmse_20190730_085420.png\t 024_XLE_1d_lnrts_20190729_131808.png\n",
      "0057_ETF_1d_boxplot_20190730_090453.png  024_XLE_1d_loss_20190729_131803.png\n",
      "0057_ETF_1d_lnrts_20190730_090454.png\t 024_XLE_1d_price_20190729_131808.png\n",
      "0057_ETF_1d_loss_20190730_090449.png\t 024_XLE_1d_rmse_20190729_131804.png\n",
      "0057_ETF_1d_price_20190730_090454.png\t 025_XLY_1d_boxplot_20190729_132656.png\n",
      "0057_ETF_1d_rmse_20190730_090449.png\t 025_XLY_1d_lnrts_20190729_132656.png\n",
      "005_EWC_1d_boxplot_20190729_105155.png\t 025_XLY_1d_loss_20190729_132651.png\n",
      "005_EWC_1d_lnrts_20190729_105156.png\t 025_XLY_1d_price_20190729_132657.png\n",
      "005_EWC_1d_loss_20190729_105150.png\t 025_XLY_1d_rmse_20190729_132651.png\n",
      "005_EWC_1d_price_20190729_105156.png\t 026_XLI_1d_boxplot_20190729_133544.png\n",
      "005_EWC_1d_rmse_20190729_105151.png\t 026_XLI_1d_lnrts_20190729_133544.png\n",
      "006_EWU_1d_boxplot_20190729_110025.png\t 026_XLI_1d_loss_20190729_133540.png\n",
      "006_EWU_1d_lnrts_20190729_110026.png\t 026_XLI_1d_price_20190729_133545.png\n",
      "006_EWU_1d_loss_20190729_110022.png\t 026_XLI_1d_rmse_20190729_133540.png\n",
      "006_EWU_1d_price_20190729_110026.png\t 027_XLP_1d_boxplot_20190729_134431.png\n",
      "006_EWU_1d_rmse_20190729_110022.png\t 027_XLP_1d_lnrts_20190729_134431.png\n",
      "007_EWH_1d_boxplot_20190729_110856.png\t 027_XLP_1d_loss_20190729_134426.png\n",
      "007_EWH_1d_lnrts_20190729_110857.png\t 027_XLP_1d_price_20190729_134432.png\n",
      "007_EWH_1d_loss_20190729_110851.png\t 027_XLP_1d_rmse_20190729_134426.png\n",
      "007_EWH_1d_price_20190729_110857.png\t 033_IWB_1d_boxplot_20190729_135314.png\n",
      "007_EWH_1d_rmse_20190729_110852.png\t 033_IWB_1d_lnrts_20190729_135315.png\n",
      "008_EWA_1d_boxplot_20190729_111727.png\t 033_IWB_1d_loss_20190729_135310.png\n",
      "008_EWA_1d_lnrts_20190729_111727.png\t 033_IWB_1d_price_20190729_135315.png\n",
      "008_EWA_1d_loss_20190729_111723.png\t 033_IWB_1d_rmse_20190729_135311.png\n",
      "008_EWA_1d_price_20190729_111728.png\t 036_IWM_1d_boxplot_20190729_140202.png\n",
      "008_EWA_1d_rmse_20190729_111723.png\t 036_IWM_1d_lnrts_20190729_140203.png\n",
      "009_EWP_1d_boxplot_20190729_112557.png\t 036_IWM_1d_loss_20190729_140157.png\n",
      "009_EWP_1d_lnrts_20190729_112557.png\t 036_IWM_1d_price_20190729_140203.png\n",
      "009_EWP_1d_loss_20190729_112552.png\t 036_IWM_1d_rmse_20190729_140157.png\n",
      "009_EWP_1d_price_20190729_112558.png\t retdata1.png\n",
      "009_EWP_1d_rmse_20190729_112553.png\t retdata2.png\n",
      "010_EWL_1d_boxplot_20190729_113424.png\t retdata3.png\n",
      "010_EWL_1d_lnrts_20190729_113424.png\t retdata4.png\n",
      "010_EWL_1d_loss_20190729_113420.png\t retdata5.png\n",
      "010_EWL_1d_price_20190729_113425.png\t retdata6.png\n",
      "010_EWL_1d_rmse_20190729_113420.png\t retdata7.png\n",
      "011_EWW_1d_boxplot_20190729_114248.png\t retdata8.png\n",
      "011_EWW_1d_lnrts_20190729_114248.png\n",
      "\n",
      "'./drive/My Drive/Portfolio/Forecasts':\n",
      "001_SPY_1d_forecasts_lnrts_20190729_101728.csv\n",
      "002_MDY_1d_forecasts_lnrts_20190729_102609.csv\n",
      "003_EWJ_1d_forecasts_lnrts_20190729_103445.csv\n",
      "004_EWG_1d_forecasts_lnrts_20190729_104321.csv\n",
      "0050_ETF_1d_forecasts_lnrts_20190730_080024.csv\n",
      "0051_ETF_1d_forecasts_lnrts_20190730_080908.csv\n",
      "0052_ETF_1d_forecasts_lnrts_20190730_081954.csv\n",
      "0053_ETF_1d_forecasts_lnrts_20190730_082833.csv\n",
      "0054_ETF_1d_forecasts_lnrts_20190730_083710.csv\n",
      "0055_ETF_1d_forecasts_lnrts_20190730_084549.csv\n",
      "0056_ETF_1d_forecasts_lnrts_20190730_085425.csv\n",
      "0057_ETF_1d_forecasts_lnrts_20190730_090454.csv\n",
      "005_EWC_1d_forecasts_lnrts_20190729_105156.csv\n",
      "006_EWU_1d_forecasts_lnrts_20190729_110026.csv\n",
      "007_EWH_1d_forecasts_lnrts_20190729_110857.csv\n",
      "008_EWA_1d_forecasts_lnrts_20190729_111728.csv\n",
      "009_EWP_1d_forecasts_lnrts_20190729_112558.csv\n",
      "010_EWL_1d_forecasts_lnrts_20190729_113425.csv\n",
      "011_EWW_1d_forecasts_lnrts_20190729_114249.csv\n",
      "012_EWI_1d_forecasts_lnrts_20190729_115117.csv\n",
      "014_EWS_1d_forecasts_lnrts_20190729_115941.csv\n",
      "015_EWD_1d_forecasts_lnrts_20190729_120800.csv\n",
      "016_EWM_1d_forecasts_lnrts_20190729_121634.csv\n",
      "017_EWO_1d_forecasts_lnrts_20190729_122519.csv\n",
      "018_EWN_1d_forecasts_lnrts_20190729_123405.csv\n",
      "019_EWK_1d_forecasts_lnrts_20190729_124249.csv\n",
      "020_DIA_1d_forecasts_lnrts_20190729_125138.csv\n",
      "021_XLF_1d_forecasts_lnrts_20190729_130031.csv\n",
      "023_XLK_1d_forecasts_lnrts_20190729_130919.csv\n",
      "024_XLE_1d_forecasts_lnrts_20190729_131808.csv\n",
      "025_XLY_1d_forecasts_lnrts_20190729_132657.csv\n",
      "026_XLI_1d_forecasts_lnrts_20190729_133545.csv\n",
      "027_XLP_1d_forecasts_lnrts_20190729_134432.csv\n",
      "033_IWB_1d_forecasts_lnrts_20190729_135315.csv\n",
      "036_IWM_1d_forecasts_lnrts_20190729_140203.csv\n",
      "\n",
      "'./drive/My Drive/中山高中 外木山影片':\n",
      "成品.mp4\n",
      "\n",
      "'./drive/My Drive/返服':\n",
      " PPT\n",
      "'UNDER LOVER - 癡情玫瑰花 ft 玖壹壹 春風 (官方Music video).mp3'\n",
      "'哆啦A夢 主題曲.mp3'\n",
      " 器材整理.docx\n",
      " 基隆校友會返鄉服務隊教案子企畫書格式-谷昭賢.docx\n",
      " 實驗原理.txt\n",
      " 新增資料夾\n",
      " 筷子兄弟-小蘋果KTV版.mp3\n",
      " 蠟筆小新OP5.mp3\n",
      " 跑流考任務.txt\n",
      " 跑流考題目.txt\n",
      " 返服.mp3\n",
      " 返服組曲TEST.mp3\n",
      "\n",
      "'./drive/My Drive/返服/PPT':\n",
      " 01-08-fb11.jpg\n",
      " 0_1423_008.jpg\n",
      " 01a14c5e652675f6fb0a8d71d796305d.jpg\n",
      "'0 (1).jpg'\n",
      "'0 (23).jpg'\n",
      "'0 (2).jpg'\n",
      " 03_sea_27_03.png\n",
      " 05-01.jpg\n",
      " 071732386490.jpg\n",
      " 0B1F081B-307E-1B90-854C-86FC8A49850B.jpg\n",
      " 0D665E47-11F5-85F7-58B5-9D22987E769D.jpg\n",
      " 0.jpg\n",
      " 1115254_orig.jpg\n",
      " 1-150415234320147.jpg\n",
      " 1302657235_1f727f8a003c6a09dded205e9b950b3e_big.jpg\n",
      " 1384312314-1252835674.jpg\n",
      " 1385736389-4039363722.jpg\n",
      " 1413783582-3492927773_n.jpg\n",
      " 1450062120-4176543179.gif\n",
      " 1468488056376-0.jpg\n",
      " 14785177662429.jpg\n",
      " 1483455669317805.jpg\n",
      " 150212-299-1-ttMdo.png\n",
      " 150212-299-2-Tlipx.png\n",
      " 150212-299-3-bj3eS.png\n",
      " 150212-299-4-u2yo8.png\n",
      " 16149.jpg\n",
      " 171051roigknioe56nggcs.jpg\n",
      " 181750242945.jpg\n",
      " 1994239.png\n",
      " 1S2491360-1.jpg\n",
      " 20070002-2-875x875.jpg\n",
      " 2015032011494655.jpg\n",
      " 20151130035718809.jpg\n",
      " 20161126123939_18.jpg\n",
      " 20170224181220_18.jpg\n",
      " 20170821202736-d3e3f10b.jpg\n",
      " 2017「北港迓媽祖」神轎「喫炮」、虎爺「顛轎」-歲次丁酉年-1080p.mp4\n",
      " 2096944_201709080548441001504836010c.jpg\n",
      " 21765735_1615465478505690_5383803432477451637_o.jpg\n",
      " 22740009937_62b5b9f2d8_c.jpg\n",
      " 25D12601-8126-6A76-EB8E-418A784E9E1B.jpg\n",
      " 272059.jpg\n",
      " 27443386345_4b97e5a799_c.jpg\n",
      " 2bed50dc.jpg\n",
      " 3291646_1.jpg\n",
      " 3ebd966044666ef4c77531b50e0eeae60912.jpg\n",
      " 4BC76FFF-D2D1-C993-B230-AFF1C884E6C2.jpg\n",
      " 4dc074dd-cd0c-4ca2-857e-7ec8b79fd360.jpg\n",
      " 4DCCAA07-3909-0177-A247-AF6EFD34DA14.jpg\n",
      " 4.jpg\n",
      " 5102733491771.jpg\n",
      " 531817_599247536799248_1843082668_n.jpg\n",
      " 54a42577139665df2e7b835838ed2257f3ba.jpg\n",
      " 5B00E919-C4EE-C9E3-E126-EC64229461D4.jpg\n",
      " 5_Sokobiki_A.jpg\n",
      " 600_1270156_2.jpg\n",
      " 600_249.jpg\n",
      " 661847787_m.jpg\n",
      " 6918320352_56f350e939.jpg\n",
      " 69c678e8-28f6-448e-bc07-c50ac6ac32ce.jpg\n",
      " 6f061d950a7b0208714f1b8065d9f2d3562cc8c8.jpg\n",
      " 75b66179d8825322fc2b01c7b809ea16.jpg\n",
      " 7.jpg\n",
      " 800h_1508068747_58de2f5513be4.jpg\n",
      " 80168103-925B-D72B-320A-83CC2AC2E62D.jpg\n",
      " 88DD2557-DF14-A14C-1EC1-F2E28A4C1C98.jpg\n",
      " 8901fe2fec68af5d18ba02838581015e8e3a.jpg\n",
      " 8a65d73caf158843776cee2aa1f3d2e117c9.jpg\n",
      " 8.jpg\n",
      " 913d30d3-5799-d8a3-f316-42354f809946.jpg\n",
      " 9F7CE348-4729-3A8C-AEE0-FF4127BC9D11.jpg\n",
      " a919deb1f0340ef858b0ae8247fadda8.jpg\n",
      " AS-24-1L.jpg\n",
      " AS-24-2L.jpg\n",
      " AS-24-3M.jpg\n",
      " AS-24-4L.jpg\n",
      " AS-24-5SS.jpg\n",
      " AS-24-6L.jpg\n",
      " b7622f711b3d1c93ef2bf0b7292b6178.jpg\n",
      " b8cf326e1cce45588f150e6a087fa76e.jpg\n",
      " BBB358C4-5374-A6F5-9951-4F47985DD631.jpg\n",
      " beach-1024x768.jpg\n",
      " c1d31500dbf4231a926220605bf7430138f1.jpg\n",
      " CC36FA61-6646-FCDC-576C-4A5F7ABDD0A2.jpg\n",
      " cover600.jpg\n",
      " current-1_1.jpg\n",
      " down_550.jpg\n",
      " DSC03458.jpg\n",
      " DSC08300.jpg\n",
      " ECFC30E6-12B6-3464-EA57-304E3C752C67.jpg\n",
      " f_10543107_1.jpg\n",
      " F58BE26A-85B3-6C97-831A-28F95CA7E43F.jpg\n",
      " flying-fish-01.jpg\n",
      " fn_GetIcon2.jpg\n",
      " fup20203.jpg\n",
      "'g38_65523 (1).jpg'\n",
      " g38_65523.jpg\n",
      " garbage-in-ocean.jpg\n",
      " geo1l11-29-728.jpg\n",
      " GP02IO4_press1.jpg\n",
      "'images (1).jpg'\n",
      " images.jpg\n",
      "'imgo (2).jpg'\n",
      " japanese-whatisafip.jpg\n",
      " link.photo.pchome.com.jpg\n",
      " maxresdefault.jpg\n",
      " OceanGarbage.mp4\n",
      " ooo...099.jpg\n",
      " photo.jpg\n",
      " picx_fpjp7087656306.jpg\n",
      " Platform.jpg\n",
      " Produce_1.mp4\n",
      " Produce_2.mp4\n",
      " Produce_3.mp4\n",
      " Produce_4.mp4\n",
      " Produce_5.mp4\n",
      " Produce_6.mp4\n",
      " rename1355929760698.jpg\n",
      " s385-3-07.jpg\n",
      "'Sea Adoration 珍愛海洋 （Full HD 1080p）.mp4'\n",
      " sy_109953937743.jpg\n",
      " sy_57484174222.jpg\n",
      " taiwam-map.jpg\n",
      " TaiwanMap.JPG\n",
      "'taiwan st.jpg'\n",
      " th.jpg\n",
      " VBkgNj6.jpg\n",
      " videoplayback.mp4\n",
      " W0911_26_1024.jpg\n",
      " water-731338_1920.jpg\n",
      " wR03xxu0Zq_1274915661.jpg\n",
      " yellow-fin-tuna-stock.jpg\n",
      "'下載 (1).jpg'\n",
      "'下載 (2).jpg'\n",
      " 下載.jpg\n",
      " 云彩上色做颜料水-7904936.jpg\n",
      " 修改.ppt\n",
      " 修改PPT.pptx\n",
      "'台灣無比精彩 - Si Mangavang拜訪號 蘭嶼大船下水.mp4'\n",
      " 唐山過台灣-曾盛俊.jpg\n",
      " 太平洋垃圾帶1-678x381.jpg\n",
      " 媽祖一號.jpg\n",
      " 媽祖事迹.mp4\n",
      " 媽祖二號.png\n",
      " 密度流+由密度差异影响而形成的洋流+大西洋+地+中+海.jpg\n",
      " 波妞的洋流之旅.pptx\n",
      " 洋流.jpg\n",
      " 海-20鏢旗魚.mp4\n",
      " 海洋.mp4\n",
      "'海洋垃圾問題嚴重 「垃圾島」面積40個台灣大-東森新聞HD.mp4'\n",
      " 【減塑行動。拯救海洋】五位明星.mp4\n",
      " 蘭嶼招魚祭_飛魚招魚祭、飛魚收藏祭、飛魚終食祭_.mp4\n",
      " 补偿流+补偿流+补偿流+补偿流.jpg\n",
      " 跟著波妞去冒險.pptx\n",
      " 飛魚傳說2.mp4\n",
      " 鱼查出的实际旗鱼白色-12650757.jpg\n",
      "\n",
      "'./drive/My Drive/返服/新增資料夾':\n",
      "'小小兵唱小蘋果 (Minions sing small apple).mp3'  '小蘋果 小小兵.mp3'\n",
      "'小小兵 癡情玫瑰花 —（UNDER LOVER玖壹壹）.mp3'\t '癡情玫瑰花 小小兵.mp3'\n",
      "\n",
      "./sample_data:\n",
      "anscombe.json\t\t      mnist_test.csv\n",
      "california_housing_test.csv   mnist_train_small.csv\n",
      "california_housing_train.csv  README.md\n"
     ]
    }
   ],
   "source": [
    "!ls -R #https://github.com/stg880631/BERT-Practice.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DID</th>\n",
       "      <th>DTEXT</th>\n",
       "      <th>QUESTIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D001</td>\n",
       "      <td>蘇軾（1037年1月8日－1101年8月24日），眉州眉山（今四川省眉山市）人，北宋時著名的...</td>\n",
       "      <td>[{'QID': 'D001Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D002</td>\n",
       "      <td>嘉佑二年（1057年），蘇軾才20歲，與弟弟蘇轍一同進京參加會考，蘇軾中進士第2名。當時主試...</td>\n",
       "      <td>[{'QID': 'D002Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D003</td>\n",
       "      <td>熙寧三年（1070年），蘇軾擔任當年度的科舉主考官，原本蘇軾要將上官均列為第一名（狀元），因...</td>\n",
       "      <td>[{'QID': 'D003Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D004</td>\n",
       "      <td>元祐元年（1086年），宋哲宗即位，高太皇太后垂簾聽政，回朝任禮部郎中、中書舍人、翰林學士，...</td>\n",
       "      <td>[{'QID': 'D004Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D006</td>\n",
       "      <td>阿拉伯之春（阿拉伯語：الثورات العربية‎）是西方主流媒體所稱的阿拉伯世界的一次...</td>\n",
       "      <td>[{'QID': 'D006Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D007</td>\n",
       "      <td>阿拉伯之春，又稱「阿拉伯的覺醒」、「阿拉伯起義」，是指自2010年年底在北非和西亞的阿拉伯國...</td>\n",
       "      <td>[{'QID': 'D007Q02', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D008</td>\n",
       "      <td>發生在突尼西亞的自焚事件是整個「阿拉伯之春」運動的導火索。2010年12月17日，26歲年輕...</td>\n",
       "      <td>[{'QID': 'D008Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D009</td>\n",
       "      <td>佔領華爾街（英語：Occupy Wall Street，或譯佔據華爾街）是一連串主要發生在紐...</td>\n",
       "      <td>[{'QID': 'D009Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D010</td>\n",
       "      <td>茉莉花革命（阿拉伯語：ثورة الياسمين‎，法語：Révolution de jas...</td>\n",
       "      <td>[{'QID': 'D010Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D011</td>\n",
       "      <td>颱風（英語：Typhoon，香港天文臺縮寫T.；日語：台風/たいふう/taifū；韓語：태풍...</td>\n",
       "      <td>[{'QID': 'D011Q01', 'QTYPE': '基礎題', 'QTEXT': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DID  ...                                          QUESTIONS\n",
       "0  D001  ...  [{'QID': 'D001Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "1  D002  ...  [{'QID': 'D002Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "2  D003  ...  [{'QID': 'D003Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "3  D004  ...  [{'QID': 'D004Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "4  D006  ...  [{'QID': 'D006Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "5  D007  ...  [{'QID': 'D007Q02', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "6  D008  ...  [{'QID': 'D008Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "7  D009  ...  [{'QID': 'D009Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "8  D010  ...  [{'QID': 'D010Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "9  D011  ...  [{'QID': 'D011Q01', 'QTYPE': '基礎題', 'QTEXT': '...\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "PdContestQuestion_A=pd.read_json('./BERT-Practice/FGC_release_A.json')\n",
    "PdContestAnswers_A=pd.read_json('./BERT-Practice/FGC_release_A_answers.json')\n",
    "#PdContestQuestion_B=pd.read_json('./BERT-Practice/FGC_release_B.json')\n",
    "#PdContestAnswers_B=pd.read_json('./BERT-Practice/FGC_release_B_answers.json')\n",
    "#PdTrainFirst=pd.read_json('./BERT-Practice/DRCD_dev.json')\n",
    "#PdTrainSecond=pd.read_json('./BERT-Practice/DRCD_test.json')\n",
    "#PdTrainThird=pd.read_json('./BERT-Practice/DRCD_training.json')\n",
    "PdCSV=pd.read_csv('./BERT-Practice/FGC_release_A_1.csv', encoding = 'big5')\n",
    "pd.get_dummies\n",
    "\n",
    "#print(PdContestQuestion_A)\n",
    "#print(PdContestAnswers_A)\n",
    "#print(PdContestQuestion_B)\n",
    "#print(PdContestAnswers_B)\n",
    "#print(PdTrainFirst)\n",
    "#print(PdTrainSecond)\n",
    "#print(PdTrainThird)\n",
    "PdContestQuestion_A.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#此處為導入資料集並丟入訓練模型的載入資料部分 完成後會刪除\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "drive.mount('/content/drive/')\n",
    "os.chdir('/content/drive/My Drive/Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    " \n",
    "\n",
    "def _get_best_indexes(logits, n_best_size=1):\n",
    "    \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    best_indexes = []\n",
    "    for i in range(len(index_and_score)):\n",
    "        if i >= n_best_size:\n",
    "            break\n",
    "        best_indexes.append(index_and_score[i][0])\n",
    "    return best_indexes\n",
    " \n",
    "\n",
    "def evaluate(dataset, model, tokenizer):\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=1)\n",
    "\n",
    "    # Eval!\n",
    "    all_results = []\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2],\n",
    "                      }\n",
    "            example_indices = batch[3]\n",
    "            outputs = model(**inputs)\n",
    "            start_logits = to_list(outputs[0][0])\n",
    "            end_logits   = to_list(outputs[1][0])\n",
    "            start_indexes = _get_best_indexes(start_logits)\n",
    "            end_indexes = _get_best_indexes(end_logits)\n",
    "    return (start_indexes, end_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "    \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "    # Because of the sliding window approach taken to scoring documents, a single\n",
    "    # token can appear in multiple documents. E.g.\n",
    "    #  Doc: the man went to the store and bought a gallon of milk\n",
    "    #  Span A: the man went to the\n",
    "    #  Span B: to the store and bought\n",
    "    #  Span C: and bought a gallon of\n",
    "    #  ...\n",
    "    #\n",
    "    # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "    # want to consider the score with \"maximum context\", which we define as\n",
    "    # the *minimum* of its left and right context (the *sum* of left and\n",
    "    # right context will always be the same, of course).\n",
    "    #\n",
    "    # In the example the maximum context for 'bought' would be span C since\n",
    "    # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "    # and 0 right context.\n",
    "    best_score = None\n",
    "    best_span_index = None\n",
    "    for (span_index, doc_span) in enumerate(doc_spans):\n",
    "        end = doc_span.start + doc_span.length - 1\n",
    "        if position < doc_span.start:\n",
    "            continue\n",
    "        if position > end:\n",
    "            continue\n",
    "        num_left_context = position - doc_span.start\n",
    "        num_right_context = end - position\n",
    "        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_span_index = span_index\n",
    "\n",
    "    return cur_span_index == best_span_index\n",
    "\n",
    "\n",
    "def convert_examples_to_features(tokenizer, question_text, doc_tokens, max_seq_length=384,\n",
    "                                 doc_stride=1, max_query_length=35,\n",
    "                                 cls_token_at_end=False,\n",
    "                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
    "                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
    "                                \n",
    "                                 cls_token_segment_id=0, pad_token_segment_id=0,\n",
    "                                 mask_padding_with_zero=True):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    query_tokens = tokenizer.tokenize(question_text)\n",
    "    #print(query_tokens)(test)\n",
    "    if len(query_tokens) > max_query_length:\n",
    "      query_tokens = query_tokens[0:max_query_length]\n",
    "    tok_to_orig_index = []\n",
    "    orig_to_tok_index = []\n",
    "    all_doc_tokens = []\n",
    "    for (i, token) in enumerate(doc_tokens):\n",
    "        orig_to_tok_index.append(len(all_doc_tokens))\n",
    "        sub_tokens = tokenizer.tokenize(token)\n",
    "        for sub_token in sub_tokens:\n",
    "            tok_to_orig_index.append(i)\n",
    "            all_doc_tokens.append(sub_token)#turn DTEXT into tokens\n",
    "        #print(sub_tokens)#(test)\n",
    "\n",
    "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "       #print(max_seq_length)(test)\n",
    "       #print(len(query_tokens))(test)\n",
    "    # We can have documents that are longer than the maximum sequence length.\n",
    "    # To deal with this we do a sliding window approach, where we take chunks\n",
    "    # of the up to our max length with a stride of `doc_stride`.\n",
    "    _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "        \"DocSpan\", [\"start\", \"length\"])\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "        length = len(all_doc_tokens) - start_offset\n",
    "        if length > max_tokens_for_doc:\n",
    "            length = max_tokens_for_doc\n",
    "        doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "        if start_offset + length == len(all_doc_tokens):\n",
    "            break\n",
    "        start_offset += min(length, doc_stride)\n",
    "\n",
    "    #input_ids = torch.tensor([0], dtype=torch.long)\n",
    "    #input_mask = torch.tensor([0], dtype=torch.long)\n",
    "    #segment_ids = torch.tensor([0], dtype=torch.long)\n",
    "    #cls_index = torch.tensor([0], dtype=torch.long)\n",
    "    #p_mask = torch.tensor([0], dtype=torch.float)\n",
    "    #example_index = torch.arange(input_ids.size(0), dtype=torch.long)\n",
    "    #tokens = []\n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "        tokens = []\n",
    "        token_to_orig_map = {}\n",
    "        token_is_max_context = {}\n",
    "        segment_ids = []\n",
    "\n",
    "        # p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)\n",
    "        # Original TF implem also keep the classification token (set to 0) (not sure why...)\n",
    "        p_mask = []\n",
    "\n",
    "        # CLS token at the beginning\n",
    "        if not cls_token_at_end:\n",
    "            tokens.append(cls_token)\n",
    "            segment_ids.append(cls_token_segment_id)\n",
    "            p_mask.append(0)\n",
    "            cls_index = 0\n",
    "\n",
    "        # Query\n",
    "        for token in query_tokens:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(sequence_a_segment_id)\n",
    "            p_mask.append(1)\n",
    "\n",
    "        # SEP token\n",
    "        tokens.append(sep_token)\n",
    "        segment_ids.append(sequence_a_segment_id)\n",
    "        p_mask.append(1)\n",
    "\n",
    "        # Paragraph\n",
    "        for i in range(doc_span.length):\n",
    "            split_token_index = doc_span.start + i\n",
    "            #print(split_token_index)******\n",
    "            token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "            is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                                   split_token_index)\n",
    "            token_is_max_context[len(tokens)] = is_max_context#type:boolean\n",
    "\n",
    "            tokens.append(all_doc_tokens[split_token_index])\n",
    "            segment_ids.append(sequence_b_segment_id)\n",
    "            p_mask.append(0)\n",
    "        paragraph_len = doc_span.length\n",
    "        #print(paragraph_len)(test)\n",
    "\n",
    "        # SEP token\n",
    "        tokens.append(sep_token)\n",
    "        segment_ids.append(sequence_b_segment_id)\n",
    "        p_mask.append(1)\n",
    "\n",
    "        # CLS token at the end\n",
    "        if cls_token_at_end:\n",
    "            tokens.append(cls_token)\n",
    "            segment_ids.append(cls_token_segment_id)\n",
    "            p_mask.append(0)\n",
    "            cls_index = len(tokens) - 1  # Index of classification token\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        #print(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "        #print(input_mask)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(pad_token)\n",
    "            input_mask.append(0 if mask_padding_with_zero else 1)\n",
    "            segment_ids.append(pad_token_segment_id)\n",
    "            p_mask.append(1)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "    input_ids = torch.tensor([input_ids], dtype=torch.long)\n",
    "    input_mask = torch.tensor([input_mask], dtype=torch.long)\n",
    "    segment_ids = torch.tensor([segment_ids], dtype=torch.long)\n",
    "    cls_index = torch.tensor([cls_index], dtype=torch.long)\n",
    "    p_mask = torch.tensor([p_mask], dtype=torch.float)\n",
    "    example_index = torch.arange(input_ids.size(0), dtype=torch.long)\n",
    "    data = TensorDataset(input_ids, input_mask, segment_ids,\n",
    "                            example_index, cls_index, p_mask)\n",
    "\n",
    "\n",
    "    ##print(\"*** Example ***\")\n",
    "    # print(\"doc_span_index: %s\" % (doc_span_index))\n",
    "    ##print(\"tokens: %s\" % \" \".join(tokens))\n",
    "    # print(\"token_to_orig_map: %s\" % \" \".join([\n",
    "    #                 \"%d:%d\" % (x, y) for (x, y) in token_to_orig_map.items()]))\n",
    "    # print(\"token_is_max_context: %s\" % \" \".join([\n",
    "    #                 \"%d:%s\" % (x, y) for (x, y) in token_is_max_context.items()\n",
    "    #             ]))\n",
    "    # print(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "    # print(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "    # print(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "\n",
    "    return data, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.4.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.85)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.5)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.38)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.11.15)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.14.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為要我們今天要跑的是中文QA 所以只有Bert可以用\n",
    "\n",
    "import torch\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig,\n",
    "                                  BertForQuestionAnswering, BertTokenizer)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = 'bert-chinese-qa'\n",
    "config_class, model_class, tokenizer_class = BertConfig, BertForQuestionAnswering, BertTokenizer\n",
    "model = model_class.from_pretrained(checkpoint).to(device)\n",
    "tokenizer = tokenizer_class.from_pretrained('bert-base-chinese', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，...</td>\n",
       "      <td>廣州的快速公交運輸系統每多久就會有一輛巴士？</td>\n",
       "      <td>10秒鐘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，...</td>\n",
       "      <td>從哪一天開始在廣州市內騎摩托車會被沒收？</td>\n",
       "      <td>2007年1月16日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，...</td>\n",
       "      <td>廣州白雲國際機場在完成第三條跑道的後八年哪一座機場也會有第三跑道？</td>\n",
       "      <td>香港國際機場</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>廣州是京廣鐵路、廣深鐵路、廣茂鐵路、廣梅汕鐵路的終點站。2009年末，武廣客運專線投入運營，...</td>\n",
       "      <td>廣珠城際鐵路平均每小時可以走多遠？</td>\n",
       "      <td>200公里</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>廣州是京廣鐵路、廣深鐵路、廣茂鐵路、廣梅汕鐵路的終點站。2009年末，武廣客運專線投入運營，...</td>\n",
       "      <td>廣九直通車從頭坐到尾約需要多久？</td>\n",
       "      <td>兩小時</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>廣州是京廣鐵路、廣深鐵路、廣茂鐵路、廣梅汕鐵路的終點站。2009年末，武廣客運專線投入運營，...</td>\n",
       "      <td>讓近江居民可以直接渡江而不需要步行過橋是因為甚麼？</td>\n",
       "      <td>渡輪線路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>廣州自古已是華南地區著名的商埠，擁有2000多年的開放貿易歷史。1970年代末中國大陸改革開...</td>\n",
       "      <td>進入國內生產總值「萬億元俱樂部」的城市第三個為？</td>\n",
       "      <td>廣州</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>廣州自古已是華南地區著名的商埠，擁有2000多年的開放貿易歷史。1970年代末中國大陸改革開...</td>\n",
       "      <td>中國第一個進入「發達」狀態的城市為？</td>\n",
       "      <td>廣州</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>廣州自古已是華南地區著名的商埠，擁有2000多年的開放貿易歷史。1970年代末中國大陸改革開...</td>\n",
       "      <td>和西班牙的人均國內生產總值水平相當的中國城市為？</td>\n",
       "      <td>廣州市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>廣州市內雨水充潤、土地肥沃，市區曾經有非常廣大的農業用地。兩千年前就已經有水稻種植的記載。宋...</td>\n",
       "      <td>廣州能夠引進了許多優良作物的品種的原因為？</td>\n",
       "      <td>曾長久作為全國性港口</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           document   ...       answer\n",
       "0  2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，...  ...         10秒鐘\n",
       "1  2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，...  ...   2007年1月16日\n",
       "2  2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，...  ...       香港國際機場\n",
       "3  廣州是京廣鐵路、廣深鐵路、廣茂鐵路、廣梅汕鐵路的終點站。2009年末，武廣客運專線投入運營，...  ...        200公里\n",
       "4  廣州是京廣鐵路、廣深鐵路、廣茂鐵路、廣梅汕鐵路的終點站。2009年末，武廣客運專線投入運營，...  ...          兩小時\n",
       "5  廣州是京廣鐵路、廣深鐵路、廣茂鐵路、廣梅汕鐵路的終點站。2009年末，武廣客運專線投入運營，...  ...         渡輪線路\n",
       "6  廣州自古已是華南地區著名的商埠，擁有2000多年的開放貿易歷史。1970年代末中國大陸改革開...  ...           廣州\n",
       "7  廣州自古已是華南地區著名的商埠，擁有2000多年的開放貿易歷史。1970年代末中國大陸改革開...  ...           廣州\n",
       "8  廣州自古已是華南地區著名的商埠，擁有2000多年的開放貿易歷史。1970年代末中國大陸改革開...  ...          廣州市\n",
       "9  廣州市內雨水充潤、土地肥沃，市區曾經有非常廣大的農業用地。兩千年前就已經有水稻種植的記載。宋...  ...   曾長久作為全國性港口\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"DRCDtraining_output3.csv\",encoding=\"MS950\")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document ', ' question ', ' answer'], dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練樣本數： 429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>江蘇，簡稱蘇，是中華人民共和國華東地區的一省，省名為江寧和蘇州的合稱，省會為南京市。江蘇省地...</td>\n",
       "      <td>江蘇的經濟何時達到巔峰?</td>\n",
       "      <td>明清</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>行李風波港鐵禁止攜帶大型樂器市民搭車引起的風波愈演態烈，到有大批示威者到大圍站示威抗議後，有...</td>\n",
       "      <td>什麼港鐵禁止攜帶大型樂器</td>\n",
       "      <td>行李風波</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>然而，世界上並非僅有美國有此獨特人文景像，在加拿大北安大略省、哥倫比亞省、紐芬蘭、拉布拉多等...</td>\n",
       "      <td>造成鬼鎮的主要因素為何?</td>\n",
       "      <td>礦業蕭條</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>腕足動物的化石物種的外形變化很大，但其外殼只有少量特徵；而現存物種的外殼變化不大，反而其軟體...</td>\n",
       "      <td>腕足動物的哪一種的特徵比另一種少？</td>\n",
       "      <td>化石物種</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>宋太祖建國時就確立了土地私有產權制度，買賣自由，並採取不抑兼併的政策，租佃經營成為重要的土地...</td>\n",
       "      <td>有人認為資本主義最早可以追朔到中國什麼朝代？</td>\n",
       "      <td>宋代</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              document  ... answer\n",
       "87   江蘇，簡稱蘇，是中華人民共和國華東地區的一省，省名為江寧和蘇州的合稱，省會為南京市。江蘇省地...  ...     明清\n",
       "117  行李風波港鐵禁止攜帶大型樂器市民搭車引起的風波愈演態烈，到有大批示威者到大圍站示威抗議後，有...  ...   行李風波\n",
       "211  然而，世界上並非僅有美國有此獨特人文景像，在加拿大北安大略省、哥倫比亞省、紐芬蘭、拉布拉多等...  ...   礦業蕭條\n",
       "256  腕足動物的化石物種的外形變化很大，但其外殼只有少量特徵；而現存物種的外殼變化不大，反而其軟體...  ...   化石物種\n",
       "263  宋太祖建國時就確立了土地私有產權制度，買賣自由，並採取不抑兼併的政策，租佃經營成為重要的土地...  ...     宋代\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#此部分為設定訓練模型 對照LEEMENG文章第一點\n",
    "df_train = pd.read_csv(\"DRCDtraining_output3.csv\",encoding=\"MS950\")\n",
    "df_train.head(10)\n",
    "\n",
    "# 只用 1% 訓練數據看看 BERT 對少量標註數據有多少幫助\n",
    "SAMPLE_FRAC = 1.00\n",
    "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9527)\n",
    "\n",
    "# 去除不必要的欄位並重新命名兩標題的欄位名\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.loc[:, ['document ', ' question ',' answer']]\n",
    "df_train.columns = ['document', 'question', 'answer']\n",
    "\n",
    "# 剔除過長的樣本以避免 BERT 無法將整個輸入序列放入記憶體不多的 GPU\n",
    "MAX_LENGTH = 256\n",
    "MAX_LENGTHQUE = 220\n",
    "\n",
    "df_train = df_train[~(df_train.document.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
    "df_train = df_train[~(df_train.question.apply(lambda x : len(x)) > MAX_LENGTHQUE)]\n",
    "# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n",
    "df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"訓練樣本數：\", len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分為設定訓練模型 對照LEEMENG文章第二點\n",
    "\"\"\"\n",
    "實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。\n",
    "此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n",
    "- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n",
    "- segments_tensor：可以用來識別兩個句子界限的 binary tensor\n",
    "- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset\n",
    "    \n",
    "class DRCDDataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
    "        self.mode = mode\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "        #self.label_map={}\n",
    "            #for i in len(df_train):\n",
    "              #updata={answer:i}\n",
    "              #self.label_map.update(updata)\n",
    "\n",
    "    # 定義回傳一筆訓練 / 測試數據的函式\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            question, document = self.df.iloc[idx, :2].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            question, document, answer = self.df.iloc[idx, :].values\n",
    "            # 將 label 文字也轉換成索引方便轉換成 tensor\n",
    "            #answer_id = answer\n",
    "              \n",
    "            #label_tensor=tf.string_to_number(answer,out_type=None,name=None)\n",
    "            #label_tensor=tf.convert_to_tensor(answer,dtype=None,dtype_hint=None,name=None)\n",
    "            #answer_id= self.tokenizer.tokenize(answer)\n",
    "            token_answer = self.tokenizer.tokenize(answer)\n",
    "            answer_ids = self.tokenizer.convert_tokens_to_ids(token_answer)\n",
    "            label_tensor = torch.Tensor(answer_ids)\n",
    "            #label_tensor = torch.tensor(answer_id)\n",
    "            #label_tensor= answer\n",
    "\n",
    "\n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_question = self.tokenizer.tokenize(question)\n",
    "        word_pieces += tokens_question + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "        \n",
    "        # 第二個句子的 BERT tokens\n",
    "        tokens_document = self.tokenizer.tokenize(document)\n",
    "        word_pieces += tokens_document + [\"[SEP]\"]\n",
    "        len_b = len(word_pieces) - len_a\n",
    "        \n",
    "        # 將整個 token 序列轉換成索引序列\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.Tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
    "        segments_tensor = torch.cuda.LongTensor([0] * len_a + [1] * len_b)#, \n",
    "                                      #  dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
    "trainset = DRCDDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "句子 1：江蘇，簡稱蘇，是中華人民共和國華東地區的一省，省名為江寧和蘇州的合稱，省會為南京市。江蘇省地跨長江、淮河南北。長江是江蘇省最大的河流，呈東西向橫穿江蘇省，省境內長度400多公里，將江蘇省分割為南北兩部分。在江蘇省境內，長江的支流有江蘇省西南部的秦淮河，在南京市匯入長江。江蘇自古以來為中國較富庶的地區。春秋後期，富強的吳國曾經稱霸中原；三國時，東吳在孫氏父子的經營下，江蘇地區大大縮小了與中原地區的差距；唐代安史之亂以後，逐步趕超中原地區。明清時，江蘇經濟文化達到巔峰，位居中國最前列。 \n",
      "句子 2： 江蘇的經濟何時達到巔峰? \n",
      "分類  ： 明清\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset 回傳的 tensors]\n",
      "tokens_tensor  ：tensor([ 101., 3736., 5979., 8024., 5080., 4935., 5979., 8024., 3221.,  704.,\n",
      "        5836.,  782., 3696., 1066., 1469., 1751., 5836., 3346., 1765., 1281.,\n",
      "        4638.,  671., 4689., 8024., 4689., 1399., 4158., 3736., 2180., 1469.,\n",
      "        5979., 2336., 4638., 1394., 4935., 8024., 4689., 3298., 4158., 1298.,\n",
      "         776., 2356.,  511., 3736., 5979., 4689., 1765., 6659., 7269., 3736.,\n",
      "         510., 3917., 3777., 1298., 1266.,  511., 7269., 3736., 3221., 3736.,\n",
      "        5979., 4689., 3297., 1920., 4638., 3777., 3837., 8024., 1439., 3346.,\n",
      "        6205., 1403., 3585., 4959., 3736., 5979., 4689., 8024., 4689., 1862.,\n",
      "        1058., 7269., 2428., 8230., 1914., 1062., 7027., 8024., 2200., 3736.,\n",
      "        5979., 4689., 1146., 1200., 4158., 1298., 1266., 1060., 6956., 1146.,\n",
      "         511., 1762., 3736., 5979., 4689., 1862., 1058., 8024., 7269., 3736.,\n",
      "        4638., 3118., 3837., 3300., 3736., 5979., 4689., 6205., 1298., 6956.,\n",
      "        4638., 4912., 3917., 3777., 8024., 1762., 1298.,  776., 2356., 1274.,\n",
      "        1057., 7269., 3736.,  511., 3736., 5979., 5632., 1367.,  809.,  889.,\n",
      "        4158.,  704., 1751., 6733., 2168., 2433., 4638., 1765., 1281.,  511.,\n",
      "        3217., 4904., 2527., 3309., 8024., 2168., 2485., 4638., 1425., 1751.,\n",
      "        3295., 5195., 4935., 7464.,  704., 1333., 8039.,  676., 1751., 3229.,\n",
      "        8024., 3346., 1425., 1762., 2113., 3694., 4266., 2094., 4638., 5195.,\n",
      "        4245.,  678., 8024., 3736., 5979., 1765., 1281., 1920., 1920., 5240.,\n",
      "        2207.,  749., 5645.,  704., 1333., 1765., 1281., 4638., 2345., 6655.,\n",
      "        8039., 1538.,  807., 2128., 1380.,  722.,  748.,  809., 2527., 8024.,\n",
      "        6852., 3635., 6634., 6631.,  704., 1333., 1765., 1281.,  511., 3209.,\n",
      "        3926., 3229., 8024., 3736., 5979., 5195., 4089., 3152., 1265., 6888.,\n",
      "        1168., 2333., 2292., 8024.,  855., 2233.,  704., 1751., 3297., 1184.,\n",
      "        1154.,  511.,  102., 3736., 5979., 4638., 5195., 4089.,  862., 3229.,\n",
      "        6888., 1168., 2333., 2292.,  136.,  102.])\n",
      "\n",
      "segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "\n",
      "label_tensor   ：tensor([3209., 3926.])\n",
      "\n",
      "--------------------\n",
      "\n",
      "[還原 tokens_tensors]\n",
      "[CLS]江蘇，簡稱蘇，是中華人民共和國華東地區的一省，省名為江寧和蘇州的合稱，省會為南京市。江蘇省地跨長江、淮河南北。長江是江蘇省最大的河流，呈東西向橫穿江蘇省，省境內長度400多公里，將江蘇省分割為南北兩部分。在江蘇省境內，長江的支流有江蘇省西南部的秦淮河，在南京市匯入長江。江蘇自古以來為中國較富庶的地區。春秋後期，富強的吳國曾經稱霸中原；三國時，東吳在孫氏父子的經營下，江蘇地區大大縮小了與中原地區的差距；唐代安史之亂以後，逐步趕超中原地區。明清時，江蘇經濟文化達到巔峰，位居中國最前列。[SEP]江蘇的經濟何時達到巔峰?[SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "document , question, answer = trainset.df.iloc[sample_idx].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \"\".join(tokens)\n",
    "\n",
    "# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{document}\n",
    "句子 2：{question}\n",
    "分類  ：{answer}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分為設定訓練模型 對照LEEMENG文章第二點\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
    "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_indexes = [s[0] for s in samples]\n",
    "    tokens_indexes_tensors = torch.stack(tokens_indexes).contiguous()\n",
    "    tokens_index_tensors=torch.cuda.LongTensor(tokens_indexes_tensors)\n",
    "    segments_indexes = [s[1] for s in samples]\n",
    "    segments_indexes_tensors = torch.stack(segments_indexes).contiguous()\n",
    "    segments_index_tensors=torch.cuda.LongTensor(segments_indexes_tensors)\n",
    "\n",
    "    \n",
    "    # 訓練集有 labels(answer)\n",
    "    if samples[0][2] is not None:\n",
    "        label_tensor = [s[2] for s in samples]\n",
    "    else:\n",
    "        label_tensor = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_index_tensors = pad_sequence(tokens_index_tensors, \n",
    "                                  batch_first=True).cuda()\n",
    "    segments_index_tensors = pad_sequence(segments_index_tensors, \n",
    "                                    batch_first=True).cuda()\n",
    "    \n",
    "    #label_tensor= pad_sequence(label_tensor, \n",
    "                                    #batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_index_tensors.shape, \n",
    "                                dtype=torch.long,device='cuda')\n",
    "    \n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_index_tensors != 0, 1)\n",
    "    masks_tensors=masks_tensors.cuda()\n",
    "    return tokens_index_tensors, segments_index_tensors, masks_tensors, label_tensor\n",
    "\n",
    "\n",
    "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
    "BATCH_SIZE = 1\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7d83b1215ec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# 訓練模式\\nmodel.train()\\n\\n# 使用 Adam Optim 更新整個分類模型的參數\\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\\n\\n\\nEPOCHS = 6  # 幸運數字\\nfor epoch in range(EPOCHS):\\n    \\n    running_loss = 0.0\\n    #cnt=0\\n    for data in trainloader:\\n     # if cnt >len(trainloader)-1:\\n     #   break\\n     \\n      for i in data:\\n        print(data[0][i])\\n        #tokens_tensor=data[0][i].to(device)\\n        #segments_tensor=data[1][i].to(device)\\n        #masks_tensor=data[2][i].to(device)\\n        #label_tensor=data[3][i].to(device)\\n        #tokens_tensors, segments_tensors, \\\\\\n        #masks_tensors, label_tensor = (t.to(device) for t in data)\\n        #start_position=label_tensor[0]\\n        #end_position=label_tensor[len(label_tensor)-1]\\n     \\n\\n        # 將參數梯度歸零\\n        optimizer.zero_grad()\\n        \\n        # forward pass\\n        outputs = model(input_ids=tokens_index_tensors, \\n                        token_type_ids=segments_index_tensors, \\n                        attention_mask=masks_tensors, \\n                        start_position=start_position,end_position=end_position)\\n\\n        loss = outputs[0]\\n        # backward\\n        loss.backward()\\n        optimizer.step()\\n\\n\\n        # 紀錄當前 batch loss\\n        running_loss += loss.item()\\n    #cnt=cnt+1    \\n    # 計算分類準確率\\n    _, acc = get_pr...\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#此部分為實際訓練模型 對照LEEMENG文章第四點\n",
    "#檢查設定\n",
    "#model.config()\n",
    "%%time\n",
    "\n",
    "# 訓練模式\n",
    "model.train()\n",
    "\n",
    "# 使用 Adam Optim 更新整個分類模型的參數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "EPOCHS = 6  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #cnt=0\n",
    "    for data in trainloader:\n",
    "     # if cnt >len(trainloader)-1:\n",
    "     #   break\n",
    "     \n",
    "      for i in data:\n",
    "        print(data[0][i])\n",
    "        #tokens_tensor=data[0][i].to(device)\n",
    "        #segments_tensor=data[1][i].to(device)\n",
    "        #masks_tensor=data[2][i].to(device)\n",
    "        #label_tensor=data[3][i].to(device)\n",
    "        #tokens_tensors, segments_tensors, \\\n",
    "        #masks_tensors, label_tensor = (t.to(device) for t in data)\n",
    "        #start_position=label_tensor[0]\n",
    "        #end_position=label_tensor[len(label_tensor)-1]\n",
    "     \n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_index_tensors, \n",
    "                        token_type_ids=segments_index_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        start_position=start_position,end_position=end_position)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "    #cnt=cnt+1    \n",
    "    # 計算分類準確率\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutctextver2(datatext,dataquestion,plen,lookback,pstartlen,answerget,ans):\n",
    "    if answerget==True and pstartlen>=len(datatext[0]):\n",
    "        print(dataquestion)\n",
    "        print(ans)\n",
    "        return\n",
    "    elif pstartlen>=len(datatext[0]) and answerget==False:\n",
    "        print(dataquestion)\n",
    "        print('[UNKNOWN]')\n",
    "        return\n",
    "    else:\n",
    "        cutt=datatext[0][pstartlen:pstartlen+plen]\n",
    "        #print(cutt)\n",
    "        data, tokens = convert_examples_to_features(tokenizer=tokenizer, question_text=dataquestion, doc_tokens=cutt)\n",
    "        start, end = evaluate(data, model, tokenizer)\n",
    "        knowans=\"\".join(tokens[start[0]: end[0]+1])\n",
    "        if (knowans!='[CLS]')and knowans!=''and knowans[0:5]!='[CLS]':\n",
    "          answerget=True\n",
    "          ansisget=knowans\n",
    "          #ans=knowans\n",
    "          return cutctextver2(datatext,dataquestion,plen,lookback,pstartlen+lookback,answerget,ansisget)\n",
    "        return cutctextver2(datatext,dataquestion,plen,lookback,pstartlen+lookback,answerget,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(PdContestQuestion_A)):\n",
    "    context=np.array(PdContestQuestion_A[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(PdContestQuestion_A[i:i+1])\n",
    "    print(dfr[0][0])\n",
    "    print(\"Q\"+str(i+1)+'.'+context[0])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        print(question[3:len(question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(PdContestQuestion_A)):\n",
    "    context=np.array(PdContestQuestion_A[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(PdContestQuestion_A[i:i+1])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        X.append([context,questioncut])\n",
    "print(X[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexttest=np.array(PdContestQuestion_A[0:1]['DTEXT'])\n",
    "dft=np.array(PdContestQuestion_A[0:1])\n",
    "question=dft[0][2][1]['QTEXT']\n",
    "print(dft[0][2][1]['QTYPE'])\n",
    "ans=\"\"\n",
    "cutctextver2(contexttest,question,256,50,0,False,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testver3\n",
    "ans=\"\"\n",
    "for i in range(0,len(PdContestQuestion_A)):\n",
    "    context=np.array(PdContestQuestion_A[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(pddata[i:i+1])\n",
    "    print(dfr[0][0])\n",
    "    print(\"Q\"+str(i+1)+'.'+context[0])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        print(dfr[0][2][j]['QTYPE'])\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        cutctextver2(context,question,256,50,0,False,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=\"\"\n",
    "for i in range(0,len(pddata)):\n",
    "    context=np.array(pddata[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(pddata[i:i+1])\n",
    "    print(dfr[0][0])\n",
    "    print(\"Q\"+str(i+1)+'.'+context[0])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        cutctextver2(context,question,256,50,0,False,ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
